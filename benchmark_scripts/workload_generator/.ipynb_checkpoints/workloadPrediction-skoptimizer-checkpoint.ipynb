{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a296ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import errno\n",
    "from msilib.schema import Error\n",
    "from time import time\n",
    "from turtle import pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def calc_avg(lst):\n",
    "    total = 0\n",
    "    for element in lst:\n",
    "        total += element\n",
    "    if len(lst) < 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return total/len(lst)\n",
    "    \n",
    "def read_data(filename):\n",
    "    nprocs = []\n",
    "    runtime = []\n",
    "    total_jobs = []\n",
    "    submit_time = []\n",
    "    \n",
    "    core_count = []\n",
    "    r = []\n",
    "    \n",
    "    \n",
    "    with open(filename) as file:\n",
    "        tsv_file = csv.reader(file, delimiter=\"\\t\")\n",
    "        field_count = 0\n",
    "        while int(field_count) < 20:\n",
    "            field_count = int(len(next(tsv_file)))\n",
    "\n",
    "        last_time = -1\n",
    "        last_hour = -1\n",
    "        job_count = 0\n",
    "        last_submitted = -1\n",
    "        i = 0\n",
    "        for line in tsv_file:\n",
    "            i += 1\n",
    "            #if i > 30000:\n",
    "                # break\n",
    "            if (float(line.__getitem__(3)) > -0.5) and (float(line.__getitem__(4)) > -0.5):\n",
    "                submitted = int(line.__getitem__(1))\n",
    "                dt = datetime.datetime.fromtimestamp(submitted)\n",
    "                time_hour = dt.hour\n",
    "\n",
    "                if last_hour == -1:\n",
    "                    last_hour = time_hour\n",
    "                    last_time = dt\n",
    "                \n",
    "                if last_hour != time_hour:\n",
    "                    runtime.append(calc_avg(r))\n",
    "                    nprocs.append(calc_avg(core_count))\n",
    "                    total_jobs.append(job_count)\n",
    "                    submit_time.append(dt.replace(minute=0, second=0, microsecond=0))\n",
    "                    last_time = dt\n",
    "                    job_count = 0\n",
    "                    core_count.clear\n",
    "                    r.clear\n",
    "                    last_submitted = -1\n",
    "                \n",
    "                core_count.append(float(line.__getitem__(4))) # number of allocated processors\n",
    "                r.append(float(line.__getitem__(3))) # runtime of the job\n",
    "                job_count += 1\n",
    "                last_submitted = submitted\n",
    "                last_hour = time_hour\n",
    "    return submit_time, runtime, nprocs, total_jobs\n",
    "\n",
    "def read_dataframe():\n",
    "    submit_time, runtime, nprocs, total_jobs = read_data('anon_jobs.gwf') #SharcNet\n",
    "    df = pd.DataFrame(list(zip(submit_time, runtime, nprocs, total_jobs)), columns=['ds', 'RunTime', 'NProcs', 'TotalJobs'])\n",
    "    # df.to_pickle('total_jobs_dataframe')\n",
    "    return df\n",
    "\n",
    "def load_dataframe():\n",
    "    return pd.read_pickle('total_jobs_dataframe')\n",
    "\n",
    "def generate_plot(x_axis, y_axis, title, x_label, y_label):\n",
    "    fig = plt.figure()\n",
    "    fig.canvas.manager.set_window_title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.plot(x_axis, y_axis)\n",
    "    plt.show()\n",
    "\n",
    "def getCpuUtilization(df: pd.DataFrame):\n",
    "    cpu = []\n",
    "    for i in range(0,24):\n",
    "        cores = df.iloc[i]['NProcs']\n",
    "        jobs = df.iloc[i]['TotalJobs']\n",
    "        cpu.append(cores*jobs/400)\n",
    "    return cpu\n",
    "\n",
    "def generate_workload(df: pd.DataFrame):\n",
    "    critical_job_rate = 0.6\n",
    "    start_time = 17\n",
    "\n",
    "    f = open('workload.csv', 'w', newline='')\n",
    "    writer = csv.writer(f, lineterminator=\"\\n\")  # use linux style line endings\n",
    "    cpuUsage = getCpuUtilization(df)\n",
    "    time_counter = 0\n",
    "    while time_counter < 86400:  # generate for whole day\n",
    "        # calculating adapted values\n",
    "        current_hour = int(time_counter / 3600)\n",
    "        adapted_hour = (current_hour + start_time) % 24         \n",
    "        #print(\"current hour: \" + str(adapted_hour))\n",
    "        #print(\"job interval adapted: \" + str(adapted_frame['InterArrivalTime']))\n",
    "\n",
    "        label = \"\"\n",
    "        if random.random() > critical_job_rate:\n",
    "            label = \"not-critical\"\n",
    "        else:\n",
    "            label = \"critical\"\n",
    "        print(\"cpu percent\", cpuUsage[adapted_hour])\n",
    "        total_cpu_usage = int(cpuUsage[adapted_hour] * 4000) # 4000 millicores rounded\n",
    "        print(\"cpu total\", total_cpu_usage)\n",
    "        total_jobs = df.iloc[adapted_hour]['TotalJobs']\n",
    "        print(\"jobs total\", total_jobs)\n",
    "        cpu_usage_per_job = total_cpu_usage/total_jobs\n",
    "        runtime = df.iloc[adapted_hour]['RunTime']\n",
    "        job_interval = int(3600/total_jobs)\n",
    "        write_data = [str(int(cpu_usage_per_job)), str(int(runtime)),\n",
    "                    str(int(job_interval)), label]\n",
    "        #print(write_data)\n",
    "        writer.writerow(write_data)\n",
    "        time_counter = int(time_counter) + int(job_interval)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "056abd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b158e387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          RunTime     NProcs  TotalJobs\n",
      "ds                                                     \n",
      "2006-01-24 17:00:00     13.600000   5.400000        5.0\n",
      "2006-01-24 18:00:00     77.000000  19.500000        9.0\n",
      "2006-01-24 19:00:00    148.625000  27.062500        2.0\n",
      "2006-01-24 20:00:00    119.105263  48.947368       22.0\n",
      "2006-01-24 21:00:00    171.384615  73.948718        1.0\n",
      "...                           ...        ...        ...\n",
      "2007-01-15 21:00:00  31829.883378   3.013483      254.0\n",
      "2007-01-15 22:00:00  31828.379609   3.013501       58.0\n",
      "2007-01-15 23:00:00  31826.919224   3.013525       57.0\n",
      "2007-01-16 00:00:00  31825.394948   3.013849       59.0\n",
      "2007-01-16 01:00:00  31825.058342   3.013981       13.0\n",
      "\n",
      "[8553 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=['ds'])\n",
    "df = df.set_index('ds')\n",
    "df = df.asfreq('H')\n",
    "df = df.interpolate('ffill')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68e66ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Params\n",
    "start_offset = 1\n",
    "offset = 1\n",
    "steps = 24\n",
    "#Build data frames for prediction\n",
    "nprocs = df[['NProcs']]\n",
    "nprocs = nprocs.rename(columns={\"NProcs\": \"y\"})\n",
    "\n",
    "runtime = df[['RunTime']]\n",
    "runtime = runtime.rename(columns={\"RunTime\": \"y\"})\n",
    "\n",
    "totaljobs = df[['TotalJobs']]\n",
    "totaljobs = totaljobs.rename(columns={\"TotalJobs\": \"y\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60153291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Offsetting and train splitting\n",
    "nprocs_offset = nprocs[start_offset:-offset]\n",
    "runtime_offset = runtime[:-offset]\n",
    "totaljobs_offset = totaljobs[:-offset]\n",
    "\n",
    "nprocs_train = nprocs_offset[:-steps]\n",
    "nprocs_test = nprocs_offset[-steps:]\n",
    "\n",
    "runtime_train = runtime_offset[:-steps]\n",
    "runtime_test = runtime_offset[-steps:]\n",
    "\n",
    "totaljobs_train = totaljobs_offset[:-steps]\n",
    "totaljobs_test = totaljobs_offset[-steps:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21c171fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 20.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop lags_grid:   0%|                                               | 0/5 [00:00<?, ?it/s]\n",
      "loop param_grid:   0%|                                              | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "loop param_grid:  25%|█████████▌                            | 1/4 [00:23<01:11, 23.99s/it]\u001b[A\n",
      "loop param_grid:  50%|███████████████████                   | 2/4 [00:59<01:01, 30.51s/it]\u001b[A\n",
      "loop param_grid:  75%|████████████████████████████▌         | 3/4 [01:45<00:37, 37.74s/it]\u001b[A\n",
      "loop param_grid: 100%|██████████████████████████████████████| 4/4 [02:43<00:00, 45.76s/it]\u001b[A\n",
      "loop lags_grid:  20%|███████▌                              | 1/5 [02:43<10:53, 163.47s/it]\u001b[A\n",
      "loop param_grid:   0%|                                              | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "loop param_grid:  25%|█████████▌                            | 1/4 [00:23<01:10, 23.55s/it]\u001b[A\n",
      "loop param_grid:  50%|███████████████████                   | 2/4 [00:58<01:00, 30.29s/it]\u001b[A\n",
      "loop param_grid:  75%|████████████████████████████▌         | 3/4 [01:44<00:37, 37.63s/it]\u001b[A\n",
      "loop param_grid: 100%|██████████████████████████████████████| 4/4 [02:43<00:00, 45.83s/it]\u001b[A\n",
      "loop lags_grid:  40%|███████████████▏                      | 2/5 [05:26<08:10, 163.39s/it]\u001b[A\n",
      "loop param_grid:   0%|                                              | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "loop param_grid:  25%|█████████▌                            | 1/4 [00:23<01:10, 23.57s/it]\u001b[A\n",
      "loop param_grid:  50%|███████████████████                   | 2/4 [00:58<01:00, 30.15s/it]\u001b[A\n",
      "loop param_grid:  75%|████████████████████████████▌         | 3/4 [01:44<00:37, 37.53s/it]\u001b[A\n",
      "loop param_grid: 100%|██████████████████████████████████████| 4/4 [02:42<00:00, 45.64s/it]\u001b[A\n",
      "loop lags_grid:  60%|██████████████████████▊               | 3/5 [08:09<05:26, 163.08s/it]\u001b[A\n",
      "loop param_grid:   0%|                                              | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "loop param_grid:  25%|█████████▌                            | 1/4 [00:23<01:10, 23.55s/it]\u001b[A\n",
      "loop param_grid:  50%|███████████████████                   | 2/4 [00:58<01:00, 30.20s/it]\u001b[A\n",
      "loop param_grid:  75%|████████████████████████████▌         | 3/4 [01:44<00:37, 37.68s/it]\u001b[A\n",
      "loop param_grid: 100%|██████████████████████████████████████| 4/4 [02:43<00:00, 45.73s/it]\u001b[A\n",
      "loop lags_grid:  80%|██████████████████████████████▍       | 4/5 [10:52<02:43, 163.08s/it]\u001b[A\n",
      "loop param_grid:   0%|                                              | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "loop param_grid:  25%|█████████▌                            | 1/4 [00:23<01:11, 23.69s/it]\u001b[A\n",
      "loop param_grid:  50%|███████████████████                   | 2/4 [00:58<01:01, 30.52s/it]\u001b[A\n",
      "loop param_grid:  75%|████████████████████████████▌         | 3/4 [01:45<00:37, 37.77s/it]\u001b[A\n",
      "loop param_grid: 100%|██████████████████████████████████████| 4/4 [02:43<00:00, 45.92s/it]\u001b[A\n",
      "loop lags_grid: 100%|██████████████████████████████████████| 5/5 [13:36<00:00, 163.28s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [30] \n",
      "  Parameters: {'max_depth': 5, 'n_estimators': 200}\n",
      "  Backtesting metric: 403471.54051222146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from skforecast.model_selection import grid_search_forecaster\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=123),\n",
    "                lags      = 10 # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [[10], [20], [30], [60], [90]]\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_grid = {'n_estimators': [100, 150, 200, 250],\n",
    "              'max_depth': [5]}\n",
    "\n",
    "results_grid = grid_search_forecaster(\n",
    "                        forecaster  = forecaster,\n",
    "                        y           = totaljobs_train['y'],\n",
    "                        param_grid  = param_grid,\n",
    "                        lags_grid   = lags_grid,\n",
    "                        steps       = steps,\n",
    "                        refit       = False,\n",
    "                        metric      = 'mean_squared_error',\n",
    "                        initial_train_size = int(len(totaljobs_train['y'])*0.5),\n",
    "                        fixed_train_size   = False,\n",
    "                        return_best = True,\n",
    "                        verbose     = False\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b044508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
