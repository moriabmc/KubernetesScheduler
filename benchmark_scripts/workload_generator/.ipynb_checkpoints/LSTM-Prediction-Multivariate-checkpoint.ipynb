{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b05c2144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>NProcs</th>\n",
       "      <th>TotalJobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-24 17:00:00</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-24 18:00:00</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-24 19:00:00</td>\n",
       "      <td>148.625000</td>\n",
       "      <td>27.062500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-24 20:00:00</td>\n",
       "      <td>119.105263</td>\n",
       "      <td>48.947368</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-24 21:00:00</td>\n",
       "      <td>171.384615</td>\n",
       "      <td>73.948718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ds     RunTime     NProcs  TotalJobs\n",
       "0 2006-01-24 17:00:00   13.600000   5.400000          5\n",
       "1 2006-01-24 18:00:00   77.000000  19.500000          9\n",
       "2 2006-01-24 19:00:00  148.625000  27.062500          2\n",
       "3 2006-01-24 20:00:00  119.105263  48.947368         22\n",
       "4 2006-01-24 21:00:00  171.384615  73.948718          1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "df = pd.read_pickle('job_traces')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eba1049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test split 5306 1769\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(df)*0.75)\n",
    "train_df,test_df = df[1:train_size], df[train_size:] \n",
    "print(\"Train - Test split\", len(train_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a7ad4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\moria\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\moria\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\moria\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\moria\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\moria\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "c:\\users\\moria\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "c:\\users\\moria\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "c:\\users\\moria\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "train = train_df\n",
    "scalers={}\n",
    "for i in train_df.columns:\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    s_s = scaler.fit_transform(train[i].values.reshape(-1,1))\n",
    "    s_s = np.reshape(s_s,len(s_s))\n",
    "    scalers['scaler_'+ i] = scaler\n",
    "    train[i] = s_s\n",
    "\n",
    "test = test_df\n",
    "for i in train_df.columns:\n",
    "    scaler = scalers['scaler_'+i]\n",
    "    s_s = scaler.transform(test[i].values.reshape(-1,1))\n",
    "    s_s = np.reshape(s_s,len(s_s))\n",
    "    scalers['scaler_'+i] = scaler\n",
    "    test[i] = s_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bba50ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_series(series, n_past, n_future):\n",
    "    # n_past ==> no of past observations\n",
    "    # n_future ==> no of future observations \n",
    "    X, y = list(), list()\n",
    "    for window_start in range(len(series)):\n",
    "        past_end = window_start + n_past\n",
    "        future_end = past_end + n_future\n",
    "        if future_end > len(series):\n",
    "              break\n",
    "        # slicing the past and future parts of the window\n",
    "        past, future = series[window_start:past_end, :], series[past_end:future_end, :]\n",
    "        X.append(past)\n",
    "        y.append(future)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bb9971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_past = 48\n",
    "n_future = 12\n",
    "n_features = 4 # Runtime, NProcs, TotalJobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94127cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = split_series(train.values, n_past, n_future)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1],n_features))\n",
    "y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], n_features))\n",
    "X_test, y_test = split_series(test.values,n_past, n_future)\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1],n_features))\n",
    "y_test = y_test.reshape((y_test.shape[0], y_test.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e98b248d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 48, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 100),        42000       ['input_1[0][0]']                \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 12, 100)      0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 12, 100)      80400       ['repeat_vector[0][0]',          \n",
      "                                                                  'lstm[0][1]',                   \n",
      "                                                                  'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 12, 4)       404         ['lstm_1[0][0]']                 \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 122,804\n",
      "Trainable params: 122,804\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# E1D1\n",
    "# n_features ==> no of features at each timestep in the data.\n",
    "\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
    "encoder_l1 = tf.keras.layers.LSTM(100, return_state=True)\n",
    "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
    "\n",
    "encoder_states1 = encoder_outputs1[1:]\n",
    "\n",
    "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs1[0])\n",
    "\n",
    "decoder_l1 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
    "decoder_outputs1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_features))(decoder_l1)\n",
    "\n",
    "model_e1d1 = tf.keras.models.Model(encoder_inputs,decoder_outputs1)\n",
    "\n",
    "model_e1d1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d9f9199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 48, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 48, 100),    42000       ['input_2[0][0]']                \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, 100),        80400       ['lstm_2[0][0]']                 \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " repeat_vector_1 (RepeatVector)  (None, 12, 100)     0           ['lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  (None, 12, 100)      80400       ['repeat_vector_1[0][0]',        \n",
      "                                                                  'lstm_2[0][1]',                 \n",
      "                                                                  'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)                  (None, 12, 100)      80400       ['lstm_4[0][0]',                 \n",
      "                                                                  'lstm_3[0][1]',                 \n",
      "                                                                  'lstm_3[0][2]']                 \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, 12, 4)       404         ['lstm_5[0][0]']                 \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 283,604\n",
      "Trainable params: 283,604\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# E2D2\n",
    "# n_features ==> no of features at each timestep in the data.\n",
    "#\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
    "encoder_l1 = tf.keras.layers.LSTM(100,return_sequences = True, return_state=True)\n",
    "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
    "encoder_states1 = encoder_outputs1[1:]\n",
    "encoder_l2 = tf.keras.layers.LSTM(100, return_state=True)\n",
    "encoder_outputs2 = encoder_l2(encoder_outputs1[0])\n",
    "encoder_states2 = encoder_outputs2[1:]\n",
    "#\n",
    "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs2[0])\n",
    "#\n",
    "decoder_l1 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
    "decoder_l2 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_l1,initial_state = encoder_states2)\n",
    "decoder_outputs2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_features))(decoder_l2)\n",
    "#\n",
    "model_e2d2 = tf.keras.models.Model(encoder_inputs,decoder_outputs2)\n",
    "#\n",
    "model_e2d2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7944c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n",
    "model_e1d1.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.Huber())\n",
    "history_e1d1=model_e1d1.fit(X_train,y_train,epochs=25,validation_data=(X_test,y_test),batch_size=32,verbose=0,callbacks=[reduce_lr])\n",
    "model_e2d2.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.Huber())\n",
    "history_e2d2=model_e2d2.fit(X_train,y_train,epochs=25,validation_data=(X_test,y_test),batch_size=32,verbose=0,callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b80934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_e1d1=model_e1d1.predict(X_test)\n",
    "pred_e2d2=model_e2d2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc34a799",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,i in enumerate(train_df.columns):\n",
    "    scaler = scalers['scaler_'+i]\n",
    "    pred1_e1d1[:,:,index]=scaler.inverse_transform(pred1_e1d1[:,:,index])\n",
    "    pred_e1d1[:,:,index]=scaler.inverse_transform(pred_e1d1[:,:,index])\n",
    "    pred1_e2d2[:,:,index]=scaler.inverse_transform(pred1_e2d2[:,:,index])\n",
    "    pred_e2d2[:,:,index]=scaler.inverse_transform(pred_e2d2[:,:,index])\n",
    "    y_train[:,:,index]=scaler.inverse_transform(y_train[:,:,index])\n",
    "    y_test[:,:,index]=scaler.inverse_transform(y_test[:,:,index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e983a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "for index,i in enumerate(train_df.columns):\n",
    "    print(i)\n",
    "    for j in range(1,6):\n",
    "        print(\"Day \",j,\":\")\n",
    "        print(\"MAE-E1D1 : \",mean_absolute_error(y_test[:,j-1,index],pred1_e1d1[:,j-1,index]),end=\", \")\n",
    "        print(\"MAE-E2D2 : \",mean_absolute_error(y_test[:,j-1,index],pred1_e2d2[:,j-1,index]))\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
